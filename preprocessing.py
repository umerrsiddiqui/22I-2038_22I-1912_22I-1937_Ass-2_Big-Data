# -*- coding: utf-8 -*-
"""preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X0PV6IETICwj5Nihc6KwQ5W7vwpEJ2Nf
"""

import json
import re

def preprocess_data(input_file, output_file):
    # Load the data from the input file
    with open(input_file, 'r') as f:
        data = json.load(f)

    # Preprocess the data
    preprocessed_data = []
    for item in data:
        # Clean and format the 'title' and 'description' fields
        cleaned_title = clean_text(item.get('title', ''))
        cleaned_description = clean_text(item.get('description', ''))

        # Remove any HTML tags from the 'feature' field
        cleaned_features = remove_html_tags(item.get('feature', ''))

        # Replace any special characters in the 'brand' field
        cleaned_brand = replace_special_characters(item.get('brand', ''))

        # Combine the preprocessed fields into a new dictionary
        preprocessed_item = {
            'asin': item.get('asin', ''),
            'title': cleaned_title,
            'description': cleaned_description,
            'feature': cleaned_features,
            'price': item.get('price', 0),
            'imageURL': item.get('imageURL', ''),
            'imageURLHighRes': item.get('imageURLHighRes', ''),
            'related': item.get('related', {}),
            'salesRank': item.get('salesRank', {}),
            'brand': cleaned_brand,
            'categories': item.get('categories', []),
            'tech1': item.get('tech1', ''),
            'tech2': item.get('tech2', ''),
            'similar': item.get('similar', [])
        }

        # Add the preprocessed item to the list
        preprocessed_data.append(preprocessed_item)

    # Write the preprocessed data to the output file
    with open(output_file, 'w') as f:
        json.dump(preprocessed_data, f, indent=4)

def clean_text(text):
    # Remove any non-alphanumeric characters
    cleaned_text = re.sub(r'[^a-zA-Z0-9\s]', '', text)
    # Convert to lowercase
    cleaned_text = cleaned_text.lower()
    return cleaned_text

def remove_html_tags(text):
    # Remove HTML tags using regex
    cleaned_text = re.sub(r'<[^>]+>', '', text)
    return cleaned_text

def replace_special_characters(text):
    # Replace special characters with spaces
    cleaned_text = re.sub(r'[^a-zA-Z0-9]', ' ', text)
    return cleaned_text

if __name__ == "__main__":
    # Input file path (replace with the actual file path)
    input_file = "amazon_metadata_sample.json"

    # Output file path (replace with the desired output file path)
    output_file = "preprocessed_data.json"

    # Preprocess the data
    preprocess_data(input_file, output_file)